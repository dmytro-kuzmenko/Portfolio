{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import sys\n",
    "\n",
    "class NormalizeInverse(torchvision.transforms.Normalize):\n",
    "    \"\"\"\n",
    "    Undoes the normalization and returns the reconstructed images in the input domain.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        mean = torch.as_tensor(mean)\n",
    "        std = torch.as_tensor(std)\n",
    "        std_inv = 1 / (std + 1e-7)\n",
    "        mean_inv = -mean * std_inv\n",
    "        super().__init__(mean=mean_inv, std=std_inv)\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return super().__call__(tensor.clone())\n",
    "\n",
    "def disp_to_term(msg):\n",
    "    sys.stdout.write(msg + '\\r')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def load_pickle(filename):\n",
    "    try:\n",
    "        p = open(filename, 'r')\n",
    "    except IOError:\n",
    "        print (\"Pickle file cannot be opened.\")\n",
    "        return None\n",
    "    try:\n",
    "        picklelicious = pk.load(p)\n",
    "    except ValueError:\n",
    "        print ('load_pickle failed once, trying again')\n",
    "        p.close()\n",
    "        p = open(filename, 'r')\n",
    "        picklelicious = pk.load(p)\n",
    "\n",
    "    p.close()\n",
    "    return picklelicious\n",
    "\n",
    "def save_pickle(data_object, filename):\n",
    "    pickle_file = open(filename, 'w')\n",
    "    pk.dump(data_object, pickle_file)\n",
    "    pickle_file.close()\n",
    "    \n",
    "def unnormalize(y, mean, std):\n",
    "    x = y.new(*y.size())\n",
    "    x[:, 0, :, :] = y[:, 0, :, :] * std[0] + mean[0]\n",
    "    x[:, 1, :, :] = y[:, 1, :, :] * std[1] + mean[1]\n",
    "    x[:, 2, :, :] = y[:, 2, :, :] * std[2] + mean[2]\n",
    "    return x\n",
    "\n",
    "def data_mean_std(train_data_gen):\n",
    "    pop_mean = []\n",
    "    pop_std = []\n",
    "    for inputs in train_data_gen:\n",
    "        # shape (batch_size, 3, height, width)\n",
    "        data , _ = inputs\n",
    "        numpy_image = data.numpy()\n",
    "\n",
    "        # shape (3,)\n",
    "        batch_mean = np.mean(numpy_image, axis=(0,2,3))\n",
    "        batch_std = np.std(numpy_image, axis=(0,2,3), ddof=1)\n",
    "\n",
    "        pop_mean.append(batch_mean)\n",
    "        pop_std.append(batch_std)\n",
    "\n",
    "    # shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "    pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "    pop_std = np.array(pop_std).mean(axis=0)\n",
    "    return pop_mean, pop_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, block, layers, latent_variable_size, nc, ngf, ndf, is_cuda=False):\n",
    "        super(VAE, self).__init__()\n",
    "        self.nc = nc # nubmer of channels\n",
    "        self.ngf = ngf # image size, i.e 200\n",
    "        self.ndf = ndf # image size, i.e 200\n",
    "        \n",
    "        self.is_cuda = is_cuda\n",
    "        \n",
    "        #Encoder\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, 512)\n",
    "        self.fc1 = nn.Linear(512 , latent_variable_size)\n",
    "        self.fc2 = nn.Linear(512 , latent_variable_size)\n",
    "        \n",
    "        \n",
    "        #Decoder\n",
    "        self.fc3 = nn.Linear(latent_variable_size, 500)\n",
    "        self.fc4 = nn.Linear(500, 25*25*10) # 14*14*32\n",
    "        self.deconv1 = nn.ConvTranspose2d(10,32, kernel_size=3, stride =2, padding=1, output_padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32,16, kernel_size=3, stride =2, padding=1, output_padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(16,3, kernel_size=3, stride =2, padding=1, output_padding=1)\n",
    "        #self.deconv4 = nn.ConvTranspose2d(16,3, kernel_size=3, stride =2, padding=1, output_padding=1)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def encode(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        w_mean = self.fc1(x)\n",
    "        w_std  = self.fc2(x)\n",
    "        return w_mean, w_std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x = self.fc3(z)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = x.view(-1, 10, 25, 25)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.deconv2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.deconv3(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if self.is_cuda:\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "    \n",
    "    def get_latent_var(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.nc, self.ndf, self.ngf))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        res = self.decode(z)\n",
    "        return res, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/prophet/Desktop/Deep Learning/VAE_pet_project'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_images = \"../datasets/anime_chars/dataset/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names_list = os.listdir(path_to_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58083"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_names_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17426 - valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i in image_names_list:\n",
    "    image  = Image.open(path_to_images + i)\n",
    "    image = image.convert('RGB')\n",
    "    width  = image.size[0]\n",
    "    height = image.size[1]\n",
    "\n",
    "    aspect = width / float(height)\n",
    "\n",
    "    ideal_width = 200\n",
    "    ideal_height = 200\n",
    "\n",
    "    ideal_aspect = ideal_width / float(ideal_height)\n",
    "\n",
    "    if aspect > ideal_aspect:\n",
    "        # Then crop the left and right edges:\n",
    "        new_width = int(ideal_aspect * height)\n",
    "        offset = (width - new_width) / 2\n",
    "        resize = (offset, 0, width - offset, height)\n",
    "    else:\n",
    "        # ... crop the top and bottom:\n",
    "        new_height = int(width / ideal_aspect)\n",
    "        offset = (height - new_height) / 2\n",
    "        resize = (0, offset, width, height - offset)\n",
    "\n",
    "    thumb = image.crop(resize).resize((ideal_width, ideal_height), Image.ANTIALIAS)\n",
    "    thumb.save(path_to_images + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.remove('../datasets/anime_chars/dataset/dataset/.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_images = \"../datasets/anime_chars/dataset/dataset_copy/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_names_list = os.listdir(path_to_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_names = image_names_list[:40657]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_names = image_names_list[40657:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58083"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_names) + len(valid_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_destin_train = '../datasets/anime_chars/dataset/train_images/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = os.listdir(path_destin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_destin_val = '../datasets/anime_chars/dataset/valid_images/valid/Abel_Bauer.jpg''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_names = os.listdir(path_destin_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_names = train_names[:5000]\n",
    "valid_names = valid_names[:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_destin_val = '../datasets/anime_chars/dataset/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_final_train = '../datasets/anime_chars/dataset/train_1k/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_final_valid = '../datasets/anime_chars/dataset/valid_1k/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_1k = tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCH = 10\n",
    "LOG_INTERVAL = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_train = '../datasets/anime_chars/dataset/train_1k/'\n",
    "path_test  = '../datasets/anime_chars/dataset/valid_1k//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_workers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageFolder(path_train, simple_transform)\n",
    "valid = ImageFolder(path_test, simple_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_gen = torch.utils.data.DataLoader(train,shuffle=True,batch_size=BATCH_SIZE,num_workers=num_workers, )\n",
    "valid_data_gen = torch.utils.data.DataLoader(valid,batch_size=BATCH_SIZE,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_sizes = {'train':len(train_data_gen.dataset),'valid':len(valid_data_gen.dataset)}\n",
    "dataloaders = {'train':train_data_gen,'valid':valid_data_gen}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 2000, 'valid': 300}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = VAE(BasicBlock, [2, 2, 2, 2], latent_variable_size=500, nc=3, ngf=200, ndf=200, is_cuda=is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstruction_function = nn.MSELoss()\n",
    "reconstruction_function.size_average = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "\n",
    "    MSE = reconstruction_function(recon_x, x)\n",
    "\n",
    "    # https://arxiv.org/abs/1312.6114 (Appendix B)\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "\n",
    "    return MSE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    batch_idx = 1\n",
    "    for data in dataloaders['train']:\n",
    "        # get the inputs\n",
    "        inputs, _ = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(inputs)\n",
    "        inputs.data = unnormalize(inputs.data,[0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])\n",
    "\n",
    "        loss = loss_function(recon_batch, inputs, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data#[0]\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(inputs), (len(dataloaders['train'])*128),\n",
    "                100. * batch_idx / len(dataloaders['train']),\n",
    "                loss.data / len(inputs)))\n",
    "        batch_idx+=1\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / (len(dataloaders['train'])*BATCH_SIZE)))\n",
    "    return train_loss / (len(dataloaders['train'])*BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    counter = 1\n",
    "    for data in dataloaders['valid']:\n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, _ = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        recon_batch, mu, logvar = model(inputs)\n",
    "        inputs.data = unnormalize(inputs.data,[0.48829153, 0.45526633, 0.41688013],[0.25974154, 0.25308523, 0.25552085])\n",
    "        test_loss += loss_function(recon_batch, inputs, mu, logvar).data\n",
    "        if((epoch + 1) % 1 == 0):\n",
    "            torchvision.utils.save_image(inputs.data, './imgs/Epoch_{}_data.jpg'.format(epoch), nrow=8, padding=2)\n",
    "            torchvision.utils.save_image(recon_batch.data, './imgs/Epoch_{}_recon.jpg'.format(epoch), nrow=8, padding=2)\n",
    "\n",
    "    test_loss /= (len(dataloaders['valid'])*128)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [500/2560 (25%)]\tLoss: 4.931206\n",
      "Train Epoch: 0 [1000/2560 (50%)]\tLoss: 1.319106\n",
      "Train Epoch: 0 [1500/2560 (75%)]\tLoss: 0.547513\n",
      "Train Epoch: 0 [2000/2560 (100%)]\tLoss: 0.297724\n",
      "====> Epoch: 0 Average loss: 3.3706\n",
      "====> Test set loss: 0.2312\n",
      "Train Epoch: 1 [500/2560 (25%)]\tLoss: 0.220206\n",
      "Train Epoch: 1 [1000/2560 (50%)]\tLoss: 0.179864\n",
      "Train Epoch: 1 [1500/2560 (75%)]\tLoss: 0.161236\n",
      "Train Epoch: 1 [2000/2560 (100%)]\tLoss: 0.143050\n",
      "====> Epoch: 1 Average loss: 0.1891\n",
      "====> Test set loss: 0.1113\n",
      "Train Epoch: 2 [500/2560 (25%)]\tLoss: 0.124587\n",
      "Train Epoch: 2 [1000/2560 (50%)]\tLoss: 0.115325\n",
      "Train Epoch: 2 [1500/2560 (75%)]\tLoss: 0.101773\n",
      "Train Epoch: 2 [2000/2560 (100%)]\tLoss: 0.099913\n",
      "====> Epoch: 2 Average loss: 0.1152\n",
      "====> Test set loss: 0.0772\n",
      "Train Epoch: 3 [500/2560 (25%)]\tLoss: 0.083481\n",
      "Train Epoch: 3 [1000/2560 (50%)]\tLoss: 0.076436\n",
      "Train Epoch: 3 [1500/2560 (75%)]\tLoss: 0.073026\n",
      "Train Epoch: 3 [2000/2560 (100%)]\tLoss: 0.062840\n",
      "====> Epoch: 3 Average loss: 0.0774\n",
      "====> Test set loss: 0.0518\n",
      "Train Epoch: 4 [500/2560 (25%)]\tLoss: 0.058337\n",
      "Train Epoch: 4 [1000/2560 (50%)]\tLoss: 0.052704\n",
      "Train Epoch: 4 [1500/2560 (75%)]\tLoss: 0.053888\n",
      "Train Epoch: 4 [2000/2560 (100%)]\tLoss: 0.045133\n",
      "====> Epoch: 4 Average loss: 0.0541\n",
      "====> Test set loss: 0.0368\n",
      "Train Epoch: 5 [500/2560 (25%)]\tLoss: 0.039194\n",
      "Train Epoch: 5 [1000/2560 (50%)]\tLoss: 0.037286\n",
      "Train Epoch: 5 [1500/2560 (75%)]\tLoss: 0.038259\n",
      "Train Epoch: 5 [2000/2560 (100%)]\tLoss: 0.034232\n",
      "====> Epoch: 5 Average loss: 0.0393\n",
      "====> Test set loss: 0.0283\n",
      "Train Epoch: 6 [500/2560 (25%)]\tLoss: 0.035175\n",
      "Train Epoch: 6 [1000/2560 (50%)]\tLoss: 0.030280\n",
      "Train Epoch: 6 [1500/2560 (75%)]\tLoss: 0.026055\n",
      "Train Epoch: 6 [2000/2560 (100%)]\tLoss: 0.024668\n",
      "====> Epoch: 6 Average loss: 0.0297\n",
      "====> Test set loss: 0.0217\n",
      "Train Epoch: 7 [500/2560 (25%)]\tLoss: 0.026575\n",
      "Train Epoch: 7 [1000/2560 (50%)]\tLoss: 0.024317\n",
      "Train Epoch: 7 [1500/2560 (75%)]\tLoss: 0.021195\n",
      "Train Epoch: 7 [2000/2560 (100%)]\tLoss: 0.020245\n",
      "====> Epoch: 7 Average loss: 0.0236\n",
      "====> Test set loss: 0.0179\n",
      "Train Epoch: 8 [500/2560 (25%)]\tLoss: 0.021010\n",
      "Train Epoch: 8 [1000/2560 (50%)]\tLoss: 0.018225\n",
      "Train Epoch: 8 [1500/2560 (75%)]\tLoss: 0.018125\n",
      "Train Epoch: 8 [2000/2560 (100%)]\tLoss: 0.019119\n",
      "====> Epoch: 8 Average loss: 0.0191\n",
      "====> Test set loss: 0.0148\n",
      "Train Epoch: 9 [500/2560 (25%)]\tLoss: 0.017340\n",
      "Train Epoch: 9 [1000/2560 (50%)]\tLoss: 0.015098\n",
      "Train Epoch: 9 [1500/2560 (75%)]\tLoss: 0.017063\n",
      "Train Epoch: 9 [2000/2560 (100%)]\tLoss: 0.013896\n",
      "====> Epoch: 9 Average loss: 0.0156\n",
      "====> Test set loss: 0.0124\n",
      "Training complete in 52m 19s\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/exp-1')\n",
    "since = time.time()\n",
    "for epoch in range(EPOCH):\n",
    "    train_loss = train(epoch)\n",
    "    test_loss = test(epoch)\n",
    "    writer.add_scalar('train_loss', train_loss, epoch)\n",
    "    writer.add_scalar('test_loss',test_loss, epoch)\n",
    "    torch.save(model.state_dict(), './models/Epoch_{}_Train_loss_{:.4f}_Test_loss_{:.4f}.pth'.format(epoch, train_loss, test_loss))\n",
    "time_elapsed = time.time() - since    \n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
